# MobileBERT를 활용한 YouTube 뮤직 비디오 댓글 감성 분석 프로젝트
# 1. 개요
이 프로젝트는 K-pop을 대표하는 명곡 소녀시대의 ‘다시 만난 세계 (Into The New World)’ 뮤직비디오에 달린 영어 댓글을 수집하고, 이를 분석하여 사람들의 감정 반응을 MobileBERT 기반 감성 분석 모델로 파악하는 것을 목표로 합니다. 선정한 곡은 한국 대중문화에서 상징적인 의미를 가지며, 글로벌 K-pop 팬들 사이에서도 지속적으로 언급되는 곡입니다. 본 프로젝트는 전 세계 사람들이 해당 곡에 대해 어떤 감정을 표현하고 있는지를 데이터 기반으로 분석하고 시각화함으로써, 문화적·정서적 반응의 흐름을 이해하고자 합니다.
# 2. 데이터
## 2-1. Google API 활용한 YouTube 댓글 원시 데이터 수집
### 📄 JSONL 원시 데이터 형식 예시

| 필드명             | 설명                                                                 |
|--------------------|----------------------------------------------------------------------|
| `author`           | 댓글 작성자의 닉네임                                                  |
| `author_channel_id`| 댓글 작성자의 YouTube 채널 ID                                         |
| `text`             | 댓글 내용 (본문)                                                      |
| `published_at`     | 댓글이 작성된 날짜 및 시간 (ISO 8601 형식)                             |
| `like_count`       | 해당 댓글이 받은 좋아요 수                                            |

#### 예시 (1개 댓글)

```json
{
  "author": "@2oqp577",
  "author_channel_id": "UCsCaKV9NGR7lwFxX0LZHB6w",
  "text": "What a fantastic time it was for the girls, k-pop and Korea. I am marked by this time when I got acquainted with Korea, it`s culture, language and history. Godspeed Korea!",
  "published_at": "2025-05-12T03:16:41Z",
  "like_count": 3
}
```
## 2-2. JSONL 데이터 형식을 변환한 CSV 형식의 2,000개의 영어 댓글 수동 데이터 라벨링
### 📄 CSV 원시 데이터 형식 예시
| 필드명    | 설명                                     |
|-----------|----------------------------------------|
| comment   | 유튜브 댓글 내용 (영어로 된 댓글 텍스트)  |
| label     | 수동 감성 라벨 (0: 부정, 1: 중립, 2: 긍정) |
#### 예시 (5개 댓글)
| **comment (댓글 내용)**                           | **label (감성 라벨)** |
|--------------------------------------------------|----------------------|
| This is not a "song", This is an "anthem"        | 2                    |
| I love this song!                                 | 2                    |
| The video quality is poor.                        | 0                    |
| Not my favorite but still good.                   | 1                    |
| The choreography is amazing!                      | 2                    |
| ... (총 2,000개의 댓글과 라벨)                     | ...                  |
## 2-3. 데이터 부가정보
![Figure_01](https://github.com/user-attachments/assets/07412978-8023-4028-8b79-010d182809b8)
# 3. 데이터 학습
## 3-1. 토큰화 결과 샘플
![token_01](https://github.com/user-attachments/assets/263df62c-83e5-4b3f-906a-1cae0dc68695)

## 3-2. 학습 결과
![result_2000_01](https://github.com/user-attachments/assets/442fb8bd-6c6a-47f5-88d7-6170120a2ee7)
## 3-3. 학습 결과 분석
**학습 및 검증 성능**

| 에폭(Epoch) | 학습 손실(Train Loss)    | 학습 정확도(Train Accuracy) | 검증 정확도(Validation Accuracy) |
|-------------|-------------------------|------------------------------|-----------------------------------|
| 1           | 0.619 (단, 73355.7421라는 비정상적 값이 기록됨) | 87.75%                       | 85.25%                            |
| 2           | 0.00719                 | 88.06%                       | 85.25%                            |
| 3           | 0.00782                 | 90.06%                       | 76.25%                            |
| 4           | 0.741                   | 90.94%                       | 85.25%                            |

---

**주요 관찰점**

**손실 및 정확도 변화**  
  - 학습 정확도는 에폭이 진행될수록 꾸준히 상승하여 90% 이상에 도달했습니다.  
  - 검증 정확도는 대체로 85% 근처에서 안정적이었으나, 3번째 에폭에서는 76.25%로 급락하여 불안정한 모습을 보였습니다.  
  - 학습 손실은 2~3번째 에폭에서 매우 낮은 값을 기록하였고, 1번째 에폭에서는 비정상적으로 높은 값이 관찰되어 손실 계산이나 로깅에 오류가 있을 가능성이 있습니다.

- **과적합 가능성**  
  - 학습 정확도가 상승하는 동안 검증 정확도가 불안정하거나 떨어지는 현상은 모델이 학습 데이터에 과적합되고 있을 가능성을 시사합니다.

- **로깅 문제**  
  - 1번째 에폭의 학습 손실 값(73355.7421)은 비정상적으로 높아 로그 오류나 계산 오류로 판단됩니다.  
  - 손실 값의 일관성이 부족하여 정확한 학습 모니터링에 어려움이 있습니다.

- **성능 및 속도**  
  - 학습 속도는 초당 약 7 에서 11 iter 이며 평가 속도는 약 25 에서 47 iter 이므로 하드웨어 사양 대비 적절한 수준입니다. 

---
## 3-4. 데이터 재학습 결과
![result_68165_01](https://github.com/user-attachments/assets/4ee8e6c4-c462-4576-8008-4f5f663efb6c)
## 3-5. 데이터 재학습 결과 분석
**높은 일반화 성능**

모델은 단 2,000개의 수작업 감성 라벨링 데이터로 학습되었음에도 불구하고 전체 68,165개의 유튜브 댓글에 대해 87.32%의 정확도를 기록하였으며 이는 다음과 같은 점에서 주목할 만합니다.

- **데이터 편향에 대한 견고함**<br>
학습에 사용된 2,000개의 라벨링 데이터는 전체 데이터의 약 2.9%에 불과하지만, 전체 데이터셋에 대한 일관된 판단을 수행했습니다. 이는 학습 데이터가 다양한 감성 표현을 충분히 포괄하거나, 모델이 적은 데이터에서도 핵심적인 패턴을 효과적으로 학습했음을 시사합니다.
- **사전학습(pretraining)의 효과**<br>
MobileBERT는 BERT 구조를 경량화한 모델이지만, 여전히 대규모 텍스트 코퍼스로 학습된 언어 이해 능력을 바탕으로 작동합니다. 즉, 사전학습된 언어 표현 능력이 감성 분류에 효과적으로 작용했다는 것을 보여줍니다.
- **라벨링 데이터의 품질**<br>
수작업으로 라벨링된 학습 데이터의 품질이 높았기 때문에, 적은 양으로도 효과적인 모델 학습이 가능했음을 의미합니다. 이는 자동화된 라벨링보다 인적 검토의 가치가 크다는 점을 뒷받침합니다.

---

### 2. **모델의 강한 전이 학습 효과**

전이 학습(Transfer Learning)은 기존에 학습된 모델을 새로운 데이터셋에 적응시키는 방식으로, 소량의 학습 데이터만으로도 좋은 성능을 낼 수 있습니다. 본 실험에서 MobileBERT는 다음과 같은 전이 학습의 이점을 극대화했습니다.

- **사전학습된 감성 관련 언어 패턴의 활용**<br>
MobileBERT는 기존의 자연어 패턴(예: 감정 표현, 긍/부정 단어의 조합 등)을 내재하고 있어, 새로운 도메인의 감성 데이터를 빠르게 적응할 수 있습니다.
- **의미 있는 학습 전이**<br>
2,000개의 라벨링 데이터가 전체 유튜브 댓글(도메인 내)의 특성을 반영하는 데 충분하다는 것은, 학습 데이터와 실제 인퍼런싱 대상 데이터 간의 **도메인 일치(domain alignment)**가 양호했음을 뜻합니다.

---

### 3. **실제 적용 가능성 확보**

정확도 87.32% 는 감성 분석 시스템에서 다음과 같은 실제 서비스에 충분히 활용할 수 있는 수준입니다.

- **콘텐츠 반응성 분석**<br>
K-pop 뮤직비디오에 달린 댓글의 감성 흐름을 분석하여 팬 반응, 여론 추이 등을 측정할 수 있습니다.
- **댓글 모니터링 시스템**<br>
부정적 댓글이 많은 콘텐츠를 탐지하거나 악성 댓글 필터링 시스템의 사전 필터링 도구로 적용 가능합니다.
- **감성 기반 추천 시스템**<br>
사용자의 긍정적 반응이 높은 콘텐츠를 추천하거나, 감성 태그 기반 큐레이션에 활용할 수 있습니다.
- **정책 적용**<br>
팬덤 중심의 커뮤니티 운영 정책 수립이나, 대중 반응에 따른 아티스트 마케팅 전략에도 적용 가능합니다.

---

