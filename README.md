# MobileBERT를 활용한 YouTube 뮤직 비디오 댓글 감성 분석 프로젝트
# 1. 개요
이 프로젝트는 K-pop을 대표하는 명곡 소녀시대의 ‘다시 만난 세계 (Into The New World)’ 뮤직비디오에 달린 영어 댓글을 수집하고, 이를 분석하여 사람들의 감정 반응을 MobileBERT 기반 감성 분석 모델로 파악하는 것을 목표로 합니다. 선정한 곡은 한국 대중문화에서 상징적인 의미를 가지며, 글로벌 K-pop 팬들 사이에서도 지속적으로 언급되는 곡입니다. 본 프로젝트는 전 세계 사람들이 해당 곡에 대해 어떤 감정을 표현하고 있는지를 데이터 기반으로 분석하고 시각화함으로써, 문화적·정서적 반응의 흐름을 이해하고자 합니다.
# 2. 데이터
## 2-1. Google API 활용한 YouTube 댓글 원시 데이터 수집
### 📄 JSONL 원시 데이터 형식 예시

| 필드명             | 설명                                                                 |
|--------------------|----------------------------------------------------------------------|
| `author`           | 댓글 작성자의 닉네임                                                  |
| `author_channel_id`| 댓글 작성자의 YouTube 채널 ID                                         |
| `text`             | 댓글 내용 (본문)                                                      |
| `published_at`     | 댓글이 작성된 날짜 및 시간 (ISO 8601 형식)                             |
| `like_count`       | 해당 댓글이 받은 좋아요 수                                            |

#### 예시 (1개 댓글)

```json
{
  "author": "@2oqp577",
  "author_channel_id": "UCsCaKV9NGR7lwFxX0LZHB6w",
  "text": "What a fantastic time it was for the girls, k-pop and Korea. I am marked by this time when I got acquainted with Korea, it`s culture, language and history. Godspeed Korea!",
  "published_at": "2025-05-12T03:16:41Z",
  "like_count": 3
}
```
## 2-2. JSONL 데이터 형식을 변환한 CSV 형식의 2,000개의 영어 댓글 수동 데이터 라벨링
### 📄 CSV 원시 데이터 형식 예시
| 필드명    | 설명                                     |
|-----------|----------------------------------------|
| comment   | 유튜브 댓글 내용 (영어로 된 댓글 텍스트)  |
| label     | 수동 감성 라벨 (0: 부정, 1: 중립, 2: 긍정) |
#### 예시 (5개 댓글)
| **comment (댓글 내용)**                           | **label (감성 라벨)** |
|--------------------------------------------------|----------------------|
| This is not a "song", This is an "anthem"        | 2                    |
| I love this song!                                 | 2                    |
| The video quality is poor.                        | 0                    |
| Not my favorite but still good.                   | 1                    |
| The choreography is amazing!                      | 2                    |
| ... (총 2,000개의 댓글과 라벨)                     | ...                  |
## 2-3. 데이터 부가정보
![Figure_01](https://github.com/user-attachments/assets/07412978-8023-4028-8b79-010d182809b8)
# 3. 데이터 학습
## 3-1. 토큰화 결과 샘플
![token_01](https://github.com/user-attachments/assets/263df62c-83e5-4b3f-906a-1cae0dc68695)

## 3-2. 학습 결과
![result_2000_01](https://github.com/user-attachments/assets/442fb8bd-6c6a-47f5-88d7-6170120a2ee7)
## 3-3. 학습 결과 분석
---

**학습 및 검증 성능**

| 에폭(Epoch) | 학습 손실(Train Loss)    | 학습 정확도(Train Accuracy) | 검증 정확도(Validation Accuracy) |
|-------------|-------------------------|------------------------------|-----------------------------------|
| 1           | 0.619 (단, 73355.7421라는 비정상적 값이 기록됨) | 87.75%                       | 85.25%                            |
| 2           | 0.00719                 | 88.06%                       | 85.25%                            |
| 3           | 0.00782                 | 90.06%                       | 76.25%                            |
| 4           | 0.741                   | 90.94%                       | 85.25%                            |

---

**주요 관찰점**

- **손실 및 정확도 변화**  
  - 학습 정확도는 에폭이 진행될수록 꾸준히 상승하여 90% 이상에 도달함.  
  - 검증 정확도는 대체로 85% 근처에서 안정적이었으나, 3번째 에폭에서는 76.25%로 급락하여 불안정한 모습을 보임.  
  - 학습 손실은 2~3번째 에폭에서 매우 낮은 값을 기록하였고, 1번째 에폭에서는 비정상적으로 높은 값이 관찰되어 손실 계산이나 로깅에 오류가 있을 가능성이 있음.

- **과적합 가능성**  
  - 학습 정확도가 상승하는 동안 검증 정확도가 불안정하거나 떨어지는 현상은 모델이 학습 데이터에 과적합되고 있을 가능성을 시사함.

- **로깅 문제**  
  - 1번째 에폭의 학습 손실 값(73355.7421)은 비정상적으로 높아 로그 오류나 계산 오류로 판단됨.  
  - 손실 값의 일관성이 부족하여 정확한 학습 모니터링에 어려움이 있음.

- **성능 및 속도**  
  - 학습 속도는 초당 약 7~11 iter, 평가 속도는 초당 약 25~47 iter로, 하드웨어 사양 대비 적절한 수준임.

---

**개선 방향 및 향후 과제**

1. **로깅 및 손실 계산 오류 수정**  
   - 손실 계산 및 로그 기록 방식을 점검하여 신뢰 가능한 값이 출력되도록 수정 필요.

2. **과적합 대응**  
   - 드롭아웃(dropout) 또는 가중치 감쇠(weight decay) 등의 정규화 기법 적용 권장.  
   - 검증 성능 기준 조기 종료(early stopping) 도입 고려.

3. **하이퍼파라미터 튜닝**  
   - 학습률, 배치 크기 등 하이퍼파라미터를 조정하여 학습 안정성 향상 시도.

4. **데이터 검증**  
   - 학습 및 검증 데이터의 분포와 라벨링 일관성 확인 필요.

5. **추가 학습 및 평가**  
   - 더 많은 에폭 학습을 진행하며 성능 변화 관찰 및 최적화 진행.

---
## 3-4.
